{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412b0116",
   "metadata": {},
   "source": [
    "# IEOR4742 Deep Learning Problem Set\n",
    "\n",
    "# Problem 6 & 7\n",
    "\n",
    "## Author: Hao Li"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fa910",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978ab5d",
   "metadata": {},
   "source": [
    "**Problem 6 (Convolutional Neural Networks)**: In the sample code example `CNN MNIST.jpynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f2326",
   "metadata": {},
   "source": [
    "**(a) add one more convolutional layer with max pooling and assess the impact of extra convolutional layer on accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74067dec",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4661c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ec655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --force-reinstall -v \"tensorflow==2.15.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b232d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading MNIST\n",
      "(60000, 784)\n",
      "(10000, 784)\n",
      "\n",
      "Spliting data\n",
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "#load data. labels are in one-hot-encoding format\n",
    "#generate original training and test data\n",
    "img_size = 28\n",
    "n_classes = 10\n",
    "\n",
    "#global_step = \n",
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "print('\\nLoading MNIST')\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.reshape(x_train, [-1, img_size*img_size])\n",
    "x_train = x_train.astype(np.float32)/255\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_test = np.reshape(x_test, [-1, img_size*img_size])\n",
    "x_test = x_test.astype(np.float32)/255\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "to_categorical = tf.keras.utils.to_categorical \n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)\n",
    "\n",
    "print('\\nSpliting data')\n",
    "\n",
    "ind = np.random.permutation(x_train.shape[0])\n",
    "x_train, y_train = x_train[ind], y_train[ind]\n",
    "\n",
    "# 10% for validation \n",
    "validatationPct = 0.1\n",
    "n = int(x_train.shape[0] * (1-validatationPct))\n",
    "x_valid = x_train[n:]\n",
    "x_train = x_train[:n]\n",
    "#\n",
    "y_valid = y_train[n:]\n",
    "y_train = y_train[:n]\n",
    "\n",
    "train_num_examples = x_train.shape[0]\n",
    "valid_num_examples = x_valid.shape[0]\n",
    "test_num_examples  = x_test.shape[0]\n",
    "\n",
    "print(train_num_examples, valid_num_examples, test_num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ecc963",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec5c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The length of window in the pooling layer\n",
    "k = 2\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.005\n",
    "training_epochs = 50\n",
    "batch_size = 200\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cce51",
   "metadata": {},
   "source": [
    "### Define 2-d Convolution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3b69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_conv2d(x, weight_shape, bias_shape):\n",
    "    \"\"\"\n",
    "    https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
    "    Computes a 2 dimentional convolution given the 4d input and filter\n",
    "    input:\n",
    "        x: [batch, in_height, in_width, in_channels]\n",
    "        weight: [filter_height, filter_width, in_channels, out_channels]\n",
    "        bias: [out_channels]\n",
    "    output:\n",
    "        The relu activation of convolution\n",
    "    \"\"\"\n",
    "    print([weight_shape[0], weight_shape[1], weight_shape[2], weight_shape[3]])\n",
    "    sizeIn = weight_shape[0] * weight_shape[1] * weight_shape[2]\n",
    "    \n",
    "    # initialize weights with data generated from a normal distribution.\n",
    "    # Sometimes, a smaller stddev can improve the accuracy significantly. Take some trials by yourself.\n",
    "    weight_init = tf.random_normal_initializer(stddev=(2.0/sizeIn)**0.5)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    \n",
    "    # initialize bias with zeros\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "    \n",
    "    # Specify the stride length to be one in all directions.\n",
    "    # padding='SAME': pad enough so the output has the same dimensions as the input tensor.\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME'), b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666f779",
   "metadata": {},
   "source": [
    "### Define Layer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16cde548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    weight_init = tf.random_normal_initializer(stddev=(2.0/weight_shape[0])**0.5)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    \n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "    \n",
    "    return tf.nn.relu(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d66f44",
   "metadata": {},
   "source": [
    "### Define Pooling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef9fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(x, k):\n",
    "    \"\"\"\n",
    "    Extracts the main information of the conv layer by performs the max pooling on the input x.\n",
    "    input:\n",
    "        x: A 4-D Tensor. [batch, in_height, in_width, in_channels]\n",
    "        k: The length of window\n",
    "    \"\"\"\n",
    "    \n",
    "    #value: A 4-D Tensor of the format specified by data_format. That is x in this case.\n",
    "    #ksize: A 1-D int Tensor of 4 elements. The size of the window for each dimension of input\n",
    "    #strides: A 1-D int Tensor of 4 elements. The stride of the sliding window for each dimension of input\n",
    "    #padding: A string, either 'VALID' or 'SAME'. Difference of 'VALID' and 'SAME' in tf.nn.max_pool:\n",
    "    #https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f15f64",
   "metadata": {},
   "source": [
    "### Define Inference (Modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c08a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x, keep_prob):\n",
    "    \"\"\"\n",
    "    define the structure of the whole network\n",
    "    input:\n",
    "        - x: a batch of pictures \n",
    "        (input shape = (batch_size*image_size))\n",
    "        - rate:  The probability that each element is dropped. For example, setting rate=0.1 would drop 10% of input elements.\n",
    "    output:\n",
    "        - a batch vector corresponding to the logits predicted by the network\n",
    "        (output shape = (batch_size*output_size)) \n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape the input into Nx28x28x1 (N # of examples & 1 due to Black-White)\n",
    "    # flatten \n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    \n",
    "    with tf.variable_scope(\"convolutional_layer_1\"):\n",
    "\n",
    "        # convolutional layer with 32 filters and spatial extent e = 5\n",
    "        # this causes in taking an input of volume with depth of 1 and producing an output tensor with 32 channels.\n",
    "        convolutional_1 = module_conv2d(x, [5, 5, 1, 32], [32])\n",
    "        \n",
    "        # output in passed to max-pooling to be compressed (k=2 non-overlapping).\n",
    "        pooling_1 = pooling(convolutional_1, k)\n",
    "\n",
    "    with tf.variable_scope(\"convolutional_layer_2\"):\n",
    "        \n",
    "        # convolutional layer with 64 filters with spatial extent e = 5\n",
    "        # taking an input tensor with depth of 32 and \n",
    "        # producing an output tensor with depth 64\n",
    "        convolutional_2 = module_conv2d(pooling_1, [5, 5, 32, 64], [64])\n",
    "        \n",
    "        # output in passed to max-pooling to be compressed (k=2 non-overlapping).\n",
    "        pooling_2 = pooling(convolutional_2, k)\n",
    "    \n",
    "    # new comvolution layer 3\n",
    "    with tf.variable_scope(\"convolutional_layer_3\"):\n",
    "    \n",
    "        # convolutional layer with a certain number of filters and kernel size\n",
    "        # since the previous layer outputs 64 channels, this layer should take 64 as input channels\n",
    "        # you can choose the number of filters (e.g., 128) and kernel size (e.g., 3x3 or 5x5)\n",
    "        convolutional_3 = module_conv2d(pooling_2, [5, 5, 64, 128], [128])\n",
    "\n",
    "        # max pooling for the third convolutional layer\n",
    "        pooling_3 = pooling(convolutional_3, k)\n",
    "#         print(\"DEBUG\", pooling_3.get_shape())\n",
    "\n",
    "    with tf.variable_scope(\"fully_connected\"):\n",
    "        \n",
    "        # pass the output of max-pooling into a Fully_Connected layer\n",
    "        # use reshape to flatten the tensor\n",
    "        # We have 128 filters\n",
    "        # To find the height & width after max-pooling:\n",
    "        # roundup((16-5)/2) + 1 = 7\n",
    "        # TensorFlow rounds down the dimensions for pooling, but here we want roundup as suggsted\n",
    "        # So, if the size after the second pooling is 7x7, it will become 4x4 after the third pooling.\n",
    "        pool_3_flat = tf.reshape(pooling_3, [-1, 4*4*128]) # change here\n",
    "        \n",
    "        # after reshaping, use fully-connected layer to compress\n",
    "        # the flattened representation into a hidden layer of size 784 (28*28)?\n",
    "        # each feature map has a height & width of 3\n",
    "        fc_1 = layer(pool_3_flat, [4*4*128, 784], [784]) # change here\n",
    "        \n",
    "        # apply dropout. You may try to add drop out after every pooling layer.\n",
    "        # outputs the input element scaled up by 1/keep_prob\n",
    "        # The scaling is so that the expected sum is unchanged\n",
    "        # fc_1_drop = tf.nn.dropout(fc_1, keep_prob)\n",
    "        fc_1_drop = tf.nn.dropout(fc_1, rate=1 - keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(fc_1_drop, [784, 10], [10])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fe038",
   "metadata": {},
   "source": [
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd8348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    \"\"\"\n",
    "    Computes softmax cross entropy between logits and labels and then the loss \n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y)  \n",
    "    #xentropy = tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5567730",
   "metadata": {},
   "source": [
    "### Define the Optimizer and Training Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5899dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    \n",
    "    # using Adam Optimizer \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50803d80",
   "metadata": {},
   "source": [
    "### Define evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70781be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -y: true value for the validation set\n",
    "    output:\n",
    "        - accuracy: accuracy on the validation set (scalar between 0 and 1)\n",
    "    \"\"\"\n",
    "    #correct prediction is a binary vector which equals one when the output and y match\n",
    "    #otherwise the vector equals 0\n",
    "    #tf.cast: change the type of a tensor into another one\n",
    "    #then, by taking the mean of the tensor, we directly have the average score, so the accuracy\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"validation_error\", (1.0 - accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11800d",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5446fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = tf.placeholder(\"float\", [None, 784])\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff5959b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 1, 32]\n",
      "[5, 5, 32, 64]\n",
      "[5, 5, 64, 128]\n",
      "WARNING:tensorflow:From /Users/georgelihao/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 04:20:31.259659: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.575854381\n",
      "Validation Error: 0.24150002002716064\n",
      "Epoch: 0002 cost = 0.520235928\n",
      "Validation Error: 0.06983333826065063\n",
      "Epoch: 0003 cost = 0.308748039\n",
      "Validation Error: 0.030166685581207275\n",
      "Epoch: 0004 cost = 0.116773811\n",
      "Validation Error: 0.02033334970474243\n",
      "Epoch: 0005 cost = 0.050859410\n",
      "Validation Error: 0.015999972820281982\n",
      "Epoch: 0006 cost = 0.046319137\n",
      "Validation Error: 0.016499996185302734\n",
      "WARNING:tensorflow:From /Users/georgelihao/anaconda3/lib/python3.11/site-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: 0007 cost = 0.045119742\n",
      "Validation Error: 0.014833331108093262\n",
      "Epoch: 0008 cost = 0.041093259\n",
      "Validation Error: 0.012333333492279053\n",
      "Epoch: 0009 cost = 0.037754454\n",
      "Validation Error: 0.014500021934509277\n",
      "Epoch: 0010 cost = 0.037692089\n",
      "Validation Error: 0.015999972820281982\n",
      "Epoch: 0011 cost = 0.038551400\n",
      "Validation Error: 0.013166666030883789\n",
      "Epoch: 0012 cost = 0.033574530\n",
      "Validation Error: 0.01466667652130127\n",
      "Epoch: 0013 cost = 0.041678301\n",
      "Validation Error: 0.01583331823348999\n",
      "Epoch: 0014 cost = 0.043339338\n",
      "Validation Error: 0.015166640281677246\n",
      "Epoch: 0015 cost = 0.038863449\n",
      "Validation Error: 0.015500009059906006\n",
      "Epoch: 0016 cost = 0.035977046\n",
      "Validation Error: 0.013666689395904541\n",
      "Epoch: 0017 cost = 0.038161916\n",
      "Validation Error: 0.01466667652130127\n",
      "Epoch: 0018 cost = 0.041305566\n",
      "Validation Error: 0.012499988079071045\n",
      "Epoch: 0019 cost = 0.039965549\n",
      "Validation Error: 0.012833356857299805\n",
      "Epoch: 0020 cost = 0.036277474\n",
      "Validation Error: 0.012000024318695068\n",
      "Epoch: 0021 cost = 0.041679047\n",
      "Validation Error: 0.014833331108093262\n",
      "Epoch: 0022 cost = 0.042634832\n",
      "Validation Error: 0.014999985694885254\n",
      "Epoch: 0023 cost = 0.041411611\n",
      "Validation Error: 0.013999998569488525\n",
      "Epoch: 0024 cost = 0.036132781\n",
      "Validation Error: 0.013666689395904541\n",
      "Epoch: 0025 cost = 0.037139410\n",
      "Validation Error: 0.012666642665863037\n",
      "Epoch: 0026 cost = 0.036670452\n",
      "Validation Error: 0.013666689395904541\n",
      "Epoch: 0027 cost = 0.030219202\n",
      "Validation Error: 0.01583331823348999\n",
      "Epoch: 0028 cost = 0.043540764\n",
      "Validation Error: 0.015666663646697998\n",
      "Epoch: 0029 cost = 0.035703960\n",
      "Validation Error: 0.014833331108093262\n",
      "Epoch: 0030 cost = 0.035820519\n",
      "Validation Error: 0.013000011444091797\n",
      "Epoch: 0031 cost = 0.039798010\n",
      "Validation Error: 0.015333354473114014\n",
      "Epoch: 0032 cost = 0.041620824\n",
      "Validation Error: 0.012666642665863037\n",
      "Epoch: 0033 cost = 0.049943933\n",
      "Validation Error: 0.012833356857299805\n",
      "Epoch: 0034 cost = 0.049289572\n",
      "Validation Error: 0.015333354473114014\n",
      "Epoch: 0035 cost = 0.047428861\n",
      "Validation Error: 0.016499996185302734\n",
      "Epoch: 0036 cost = 0.041155358\n",
      "Validation Error: 0.01849997043609619\n",
      "Epoch: 0037 cost = 0.043102723\n",
      "Validation Error: 0.012833356857299805\n",
      "Epoch: 0038 cost = 0.041096584\n",
      "Validation Error: 0.014166653156280518\n",
      "Epoch: 0039 cost = 0.037527904\n",
      "Validation Error: 0.015166640281677246\n",
      "Epoch: 0040 cost = 0.043996294\n",
      "Validation Error: 0.017000019550323486\n",
      "Epoch: 0041 cost = 0.048637376\n",
      "Validation Error: 0.014500021934509277\n",
      "Epoch: 0042 cost = 0.044398691\n",
      "Validation Error: 0.012666642665863037\n",
      "Epoch: 0043 cost = 0.049406960\n",
      "Validation Error: 0.013166666030883789\n",
      "Epoch: 0044 cost = 0.048317222\n",
      "Validation Error: 0.01433330774307251\n",
      "Epoch: 0045 cost = 0.042660122\n",
      "Validation Error: 0.011500000953674316\n",
      "Epoch: 0046 cost = 0.046937158\n",
      "Validation Error: 0.012499988079071045\n",
      "Epoch: 0047 cost = 0.043061468\n",
      "Validation Error: 0.012333333492279053\n",
      "Epoch: 0048 cost = 0.036366054\n",
      "Validation Error: 0.012333333492279053\n",
      "Epoch: 0049 cost = 0.044051876\n",
      "Validation Error: 0.012833356857299805\n",
      "Epoch: 0050 cost = 0.052494276\n",
      "Validation Error: 0.012666642665863037\n",
      "Optimization Done\n",
      "Test Accuracy: 0.9876\n",
      "Execution time was 1195.405\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    if not os.path.isdir('./logs/'):\n",
    "        os.makedirs('./logs/')\n",
    "    log_files_path = './logs/'\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.variable_scope(\"MNIST_convoultional_model\"):\n",
    "            \n",
    "            #neural network definition\n",
    "            \n",
    "            #the input variables are first define as placeholder \n",
    "            # a placeholder is a variable/data which will be assigned later \n",
    "            # MNIST data image of shape 28*28=784\n",
    "            x = tf.placeholder(\"float\", [None, 784]) \n",
    "            # 0-9 digits recognition\n",
    "            y = tf.placeholder(\"float\", [None, 10])  \n",
    "            \n",
    "            # dropout probability\n",
    "            keep_prob = tf.placeholder(tf.float32) \n",
    "            \n",
    "            #the network is defined using the inference function defined above in the code\n",
    "            output = inference(x, keep_prob)\n",
    "            cost = loss(output, y)\n",
    "            \n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            \n",
    "            \n",
    "            train_op = training(cost, global_step)\n",
    "            \n",
    "            \n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            eval_op = evaluate(output, y)\n",
    "            summary_op = tf.summary.merge_all()\n",
    "            saver = tf.train.Saver()\n",
    "            sess = tf.Session()\n",
    "            \n",
    "            summary_writer = tf.summary.FileWriter(log_files_path, sess.graph)\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "            \n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.0\n",
    "                \n",
    "                total_batch = int((train_num_examples+batch_size-1) / batch_size)\n",
    "                \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "                    \n",
    "                    start = i * batch_size\n",
    "                    end = min(train_num_examples, start + batch_size)\n",
    "                    minibatch_x = x_train[start:end]\n",
    "                    minibatch_y = y_train[start:end]\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y, keep_prob: 0.25})\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y, keep_prob: 0.25})/total_batch\n",
    "                \n",
    "                \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    \n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:0.9f}\".format(avg_cost))\n",
    "                    \n",
    "                    #probability dropout of 1 during validation\n",
    "                    accuracy = sess.run(eval_op, feed_dict={x: x_valid, y:y_valid, keep_prob: 1})\n",
    "                    print(\"Validation Error:\", (1 - accuracy))\n",
    "                    \n",
    "                    # probability dropout of 0.25 during training\n",
    "                    summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y, keep_prob: 0.25})\n",
    "                    summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "                    \n",
    "                    saver.save(sess, log_files_path + 'model-checkpoint', global_step=global_step)\n",
    "                    \n",
    "            print(\"Optimization Done\")\n",
    "                    \n",
    "            accuracy = sess.run(eval_op, feed_dict={x: x_test, y: y_test, keep_prob: 1})\n",
    "            print(\"Test Accuracy:\", accuracy)\n",
    "                    \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Execution time was %0.3f' % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a6607",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "1. **Accuracy Comparison**:\n",
    "\n",
    "* **Two Convolutional Layers**: The model achieved a high test accuracy of approximately 98.82%. The validation error decreased steadily over epochs, indicating that the model was learning effectively.\n",
    "\n",
    "* **Three Convolutional Layers**: With the addition of the third layer, the model also achieved a high test accuracy of approximately 98.76%. The validation error similarly decreased over time, but the overall training process showed higher initial error rates compared to the two-layer model.\n",
    "\n",
    "2. **Training Dynamics**:\n",
    "\n",
    "* **Learning Curve**: The three-layer model initially had higher validation errors and required more epochs to reach a low error rate. This suggests that the added complexity of the model might have made the initial learning process slightly more challenging.\n",
    "\n",
    "* **Convergence**: Both models eventually converged to a low validation error, but the three-layer model showed a bit more fluctuation in validation error, which might indicate sensitivity to training parameters or a higher propensity for overfitting.\n",
    "\n",
    "3. **Overfitting and Model Stability**:\n",
    "\n",
    "* **Potential Overfitting**: Deeper models like the three-layer CNN have more parameters and are more prone to overfitting. This might explain the occasional instances of extremely low accuracy in some training runs. Overfitting occurs when the model learns the noise in the training data instead of generalizing from the patterns.\n",
    "\n",
    "* **Result Stability**: The variability in results across different runs suggests that the three-layer model's performance is less stable compared to the two-layer model. In some cases, I got results that yields the accuracy with onlg single digits, which is extremely low. This instability could be due to the more complex decision boundaries that the model is trying to learn.\n",
    "\n",
    "4. **Impact on Accuracy**:\n",
    "\n",
    "* **Performance Gain**: The addition of the third layer did not result in a significant improvement in accuracy. Both models achieved similar high accuracies, indicating that for the MNIST dataset, a two-layer model is quite sufficient.\n",
    "\n",
    "* **Computational Efficiency**: The three-layer model is more computationally intensive due to the additional layer. Without a corresponding increase in accuracy, the extra computational cost may not be justified.\n",
    "\n",
    "5. **Conclusion**:\n",
    "\n",
    "* **Model Complexity vs. Dataset Complexity**: The MNIST dataset, being relatively simple, may not require very deep networks. The additional layer did not contribute significantly to accuracy improvement, suggesting that the two-layer model is already quite capable of capturing the relevant features in the data.\n",
    "\n",
    "* **Randomness in Training**: Deep learning models are subject to randomness in weight initialization, mini-batch selection during training, etc. This randomness can lead to variability in training results, especially in more complex models.\n",
    "\n",
    "* **Recommendation**: For similar tasks with comparable dataset complexity, starting with a simpler model (like the two-layer CNN) might be more efficient. Deeper models can be considered if the task complexity increases or if the simpler models plateau in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6995edaf",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b3a8a",
   "metadata": {},
   "source": [
    "**(b) what are the number of parameters we are trying to learn in the original code and the new one with an extra layer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3642af8",
   "metadata": {},
   "source": [
    "## Parameters in a Convolutional Layer:\n",
    "   - For a convolutional layer, the number of parameters is determined by the size of the filters (or kernels), the number of filters, and the number of input channels. The formula is:\n",
    "   - $\\text{Parameters} =(\\text{Filter Height} × \\text{Filter Width} × \\text{Input Channels} + 1) × \\text{Number of Filters}$\n",
    "   - The \"+1\" accounts for the bias term for each filter.\n",
    "\n",
    "## Original CNN (Two Convolutional Layers):\n",
    "\n",
    "1. **First Convolutional Layer**: \n",
    "   - Filters: 32, Filter Size: 5x5, Input Channels: 1 (grayscale image)\n",
    "   - Parameters: $(5 \\times 5 \\times 1 + 1) \\times 32 = 832$\n",
    "\n",
    "2. **Second Convolutional Layer**: \n",
    "   - Filters: 64, Filter Size: 5x5, Input Channels: 32 (output from first layer)\n",
    "   - Parameters: $(5 \\times 5 \\times 32 + 1) \\times 64 = 51,264$\n",
    "\n",
    "3. **First Fully Connected Layer**: \n",
    "   - Assuming the image size reduces to 7x7 after pooling, and there are 64 output channels from the last convolutional layer\n",
    "   - Input Units: $7 \\times 7 \\times 64$, Output Units: 784 (as per your model)\n",
    "   - Parameters: $(7 \\times 7 \\times 64 \\times 784) + 784 = 2,459,408$\n",
    "\n",
    "4. **Output Layer**: \n",
    "   - Input Units: 784, Output Units: 10 (number of classes for MNIST)\n",
    "   - Parameters: $784 \\times 10 + 10 = 7850$\n",
    "   \n",
    "5. **Total Parameters in the Original CNN**:\n",
    "   - $\\text{Total} = 832 + 51,264 + 2,459,408 + 7,850 = 2,519,354$\n",
    "\n",
    "## Modified CNN (Three Convolutional Layers):\n",
    "\n",
    "1. **First and Second Convolutional Layers**: \n",
    "   - The calculations remain the same as the original model.\n",
    "\n",
    "2. **Third Convolutional Layer**: \n",
    "   - Filters: 128, Filter Size: 5x5, Input Channels: 64\n",
    "   - Parameters: $(5 \\times 5 \\times 64 + 1) \\times 128 = 204,928$\n",
    "\n",
    "3. **First Fully Connected Layer** (adjusted for the output of the third convolutional layer):\n",
    "   - Assuming the image size reduces to 4x4 after the third pooling layer\n",
    "   - Input Units: $4 \\times 4 \\times 128$, Output Units: 784\n",
    "   - Parameters: $(4 \\times 4 \\times 128 \\times 784) + 784 = 1,606,416$\n",
    "\n",
    "4. **Output Layer**: \n",
    "   - The calculation remains the same as the original model.\n",
    "   - Input Units: 784, Output Units: 10 (number of classes for MNIST)\n",
    "   - Parameters: $784 \\times 10 + 10 = 7850$\n",
    "\n",
    "5. **Total Parameters in the New CNN**:\n",
    "\n",
    "   - The total number of parameters for each model can be calculated by summing up the parameters from all the convolutional layers and fully connected layers.\n",
    "   - $\\text{Total} = 832 + 51,264 + 204,928 + 1,606,416 + 7,850 = 1,871,290$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc2816",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2051536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5*5*1+1)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0227983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51264"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5*5*32+1)*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4897edaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2459408"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7*7*64*784)+784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc96180d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7850"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*10+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0b6a7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2519354"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "832+51264+2459408+7850"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1d90d",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cce1e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204928"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5*5*64+1)*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "657b7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606416"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4*4*128*784)+784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9934d569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7850"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*10+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd5af917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1871290"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "832+51264+204928+1606416+7850"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733b1b1",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8be048",
   "metadata": {},
   "source": [
    "## Problem 7 (Batch Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a01cb",
   "metadata": {},
   "source": [
    "**Problem 7: For Problem 6, assess the impact of batch normalization on learning (speed & accuracy)?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
