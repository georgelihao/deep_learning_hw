{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XW5zkgqrBQzh"
   },
   "source": [
    "# Important: You have to run logistic_regression_multi_2Layer.ipynb first before running this code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T01:58:49.569152Z",
     "start_time": "2018-09-20T01:58:48.721454Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5s3xwscaBQzl",
    "outputId": "1b240c36-c4f5-4967-8c74-f7a4f492423a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print(tf.__version__)\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# generate original training and test data\n",
    "img_size = 28\n",
    "n_classes = 10\n",
    "\n",
    "#MNIST data image of shape 28*28=784\n",
    "input_size = 784\n",
    "\n",
    "# 0-9 digits recognition (labels)\n",
    "output_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading MNIST\n",
      "\n",
      "Spliting data\n",
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------\n",
    "#option 1: load MNIST dataset \n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "#option 2: load MNIST dataset \n",
    "print('\\nLoading MNIST')\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.reshape(x_train, [-1, img_size*img_size])\n",
    "x_train = x_train.astype(np.float32)/255\n",
    "\n",
    "x_test = np.reshape(x_test, [-1, img_size*img_size])\n",
    "x_test = x_test.astype(np.float32)/255\n",
    "\n",
    "to_categorical = tf.keras.utils.to_categorical \n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)\n",
    "\n",
    "print('\\nSpliting data')\n",
    "\n",
    "ind = np.random.permutation(x_train.shape[0])\n",
    "x_train, y_train = x_train[ind], y_train[ind]\n",
    "\n",
    "# 10% for validation \n",
    "validatationPct = 0.1\n",
    "n = int(x_train.shape[0] * (1-validatationPct))\n",
    "x_valid = x_train[n:]\n",
    "x_train = x_train[:n]\n",
    "#\n",
    "y_valid = y_train[n:]\n",
    "y_train = y_train[:n]\n",
    "\n",
    "train_num_examples = x_train.shape[0]\n",
    "valid_num_examples = x_valid.shape[0]\n",
    "test_num_examples  = x_test.shape[0]\n",
    "\n",
    "print(train_num_examples, valid_num_examples, test_num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-19T22:03:55.082812Z",
     "start_time": "2018-09-19T22:03:55.079720Z"
    },
    "colab_type": "text",
    "id": "nMuFUzhbBQzt"
   },
   "source": [
    "# Parameters (have to be consistent with logistic_regression_multi_2layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T01:59:02.285613Z",
     "start_time": "2018-09-20T01:59:02.277606Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cAGZzNr5BQzv"
   },
   "outputs": [],
   "source": [
    "#Network Hidden Layers Parameters\n",
    "n_hidden_1 = 200\n",
    "n_hidden_2 = 300\n",
    "\n",
    "#Input and Output Layers Parameters\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "#change it to your own path \n",
    "#log_files_path = './checkpoints/'\n",
    "#log_files_path = 'C:/Users/Ali/logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmeMrQaABQzz"
   },
   "source": [
    "# Definition of the Layer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T01:59:03.814451Z",
     "start_time": "2018-09-20T01:59:03.796629Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VPF3sK0QBQz1"
   },
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    print('inside layer')\n",
    "    \n",
    "    # comes from the study by He et al. for ReLU layers\n",
    "    w_std = (2.0/weight_shape[0])**0.5\n",
    "    \n",
    "    #initialization of the weights\n",
    "    w_0 = tf.random_normal_initializer(stddev=w_std)\n",
    "\n",
    "    b_0 = tf.constant_initializer(value=0)\n",
    "    \n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=w_0)\n",
    "    b = tf.get_variable(\"b\", bias_shape,   initializer=b_0)\n",
    "    \n",
    "    # different activation functions\n",
    "    # you can try either \n",
    "\n",
    "    #return tf.nn.relu(tf.matmul(x, W) + b)\n",
    "    return tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHvf_47nBQz5"
   },
   "source": [
    "# Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T01:59:05.120581Z",
     "start_time": "2018-09-20T01:59:05.107111Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "u5G3DQ_EBQz7"
   },
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    \"\"\"\n",
    "    define the whole network (2 hidden layers + output layers)\n",
    "    input:\n",
    "        - a batch of pictures \n",
    "        (input shape = (batch_size*image_size))\n",
    "    output:\n",
    "        - a batch vector corresponding to the logits predicted by the network\n",
    "        (output shape = (batch_size*output_size)) \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_layer_1\"):\n",
    "        hidden_1 = layer(x, [input_size, n_hidden_1], [n_hidden_1])\n",
    "        #print([input_size, n_hidden_1])\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_layer_2\"):\n",
    "        hidden_2 = layer(hidden_1, [n_hidden_1, n_hidden_2], [n_hidden_2])\n",
    "        #print([n_hidden_1, n_hidden_2])\n",
    "     \n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_2, [n_hidden_2, output_size], [output_size])\n",
    "        #print([n_hidden_2, output_size])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtrNWTjABQz_"
   },
   "source": [
    "# Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T01:59:07.775648Z",
     "start_time": "2018-09-20T01:59:07.769327Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9auCMNBxBQ0A"
   },
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    \"\"\"\n",
    "    Computes softmax cross entropy between logits and labels and then the loss \n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the inference function \n",
    "        - y: true value of the sample batch\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    #Computes softmax cross entropy between logits and labels.\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgPL0LIWBQ0F"
   },
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T01:59:09.333152Z",
     "start_time": "2018-09-20T01:59:09.003257Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5TiBa3yKBQ0H",
    "outputId": "ce1ccbea-0e1e-44da-b55a-27135754e243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside layer\n",
      "inside layer\n",
      "inside layer\n",
      "WARNING:tensorflow:From <ipython-input-6-8bb28c0902cf>:15: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./logs/multi_layer/model-checkpoint-98280\n",
      "inside layer\n",
      "inside layer\n",
      "inside layer\n",
      "[7.712475, 2.555974]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "            \n",
    "#the input variables are first define as placeholder \n",
    "# a placeholder is a variable/data which will be assigned later \n",
    "# image vector & label\n",
    "x = tf.placeholder(\"float\", [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(\"float\", [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "\n",
    "if not os.path.isdir('./logs/'):\n",
    "    os.makedirs('./logs/')\n",
    "log_files_path = './logs/'\n",
    "    \n",
    "#defines a session\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"multi_layer_2\", reuse=tf.AUTO_REUSE):\n",
    "    #opt neural network definition\n",
    "    \n",
    "    #the network is defined using the inference function defined above in the code\n",
    "    output_opt = inference(x)\n",
    "    \n",
    "    #compute the cost \n",
    "    cost_opt = loss(output_opt, y)\n",
    "    \n",
    "    saver = tf.train.Saver() \n",
    "    \n",
    "    var_list_opt = [\"hidden_layer_1/W\", \"hidden_layer_1/b\",\n",
    "                    \"hidden_layer_2/W\", \"hidden_layer_2/b\", \n",
    "                    \"output/W\", \"output/b\"]\n",
    "    \n",
    "    var_list_opt = [tf.get_variable(v) for v in var_list_opt]\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # restore values of parameters saved previously\n",
    "    # remember to download the model checkpoints files from canvas and save them in the corresponding path\n",
    "    \n",
    "    # important: your check point number may be different from this one\n",
    "    saver.restore(sess, log_files_path + 'multi_layer_2/model-checkpoint-98280')\n",
    "    #----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    \n",
    "with tf.variable_scope(\"multi_layer_init\", reuse=tf.AUTO_REUSE):\n",
    "    #rand neural network definition\n",
    "    \n",
    "    #the network is defined using the inference function defined above in the code\n",
    "    output_rand = inference(x)\n",
    "    #compute the rand cost\n",
    "    cost_rand = loss(output_rand, y)\n",
    "    \n",
    "    var_list_rand = [\"hidden_layer_1/W\", \"hidden_layer_1/b\", \n",
    "                     \"hidden_layer_2/W\", \"hidden_layer_2/b\", \n",
    "                     \"output/W\", \"output/b\"]\n",
    "    \n",
    "    var_list_rand = [tf.get_variable(v) for v in var_list_rand]\n",
    "    \n",
    "    #initialization of the variables\n",
    "    init_op = tf.variables_initializer(var_list_rand)\n",
    "    \n",
    "    sess.run(init_op)\n",
    "\n",
    "    \n",
    "\n",
    "#dictionary for the test dataset \n",
    "#used to evaluate accuracy \n",
    "feed_dict = {\n",
    "        x: x_test,\n",
    "        y: y_test,\n",
    "}\n",
    "\n",
    "\n",
    "#compute the loss for opt and rand networks\n",
    "print(sess.run([cost_opt, cost_rand], feed_dict=feed_dict))\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"multi_layer_inter\") as scope:\n",
    "    #initialize the placeholder alpha coefficient \n",
    "    #a placeholder is a variable/data which will be assigned later \n",
    "    alpha = tf.placeholder(\"float\", [1, 1])\n",
    "    \n",
    "    #the coefficients of the opt and rand networks are modulated with the alpha coefficient\n",
    "    h1_W_inter = var_list_opt[0] * (1.0 - alpha) + var_list_rand[0] * (alpha)\n",
    "    h1_b_inter = var_list_opt[1] * (1.0 - alpha) + var_list_rand[1] * (alpha)\n",
    "    #\n",
    "    h2_W_inter = var_list_opt[2] * (1.0 - alpha) + var_list_rand[2] * (alpha)\n",
    "    h2_b_inter = var_list_opt[3] * (1.0 - alpha) + var_list_rand[3] * (alpha)\n",
    "    #\n",
    "    o_W_inter  = var_list_opt[4] * (1.0 - alpha) + var_list_rand[4] * (alpha)\n",
    "    o_b_inter  = var_list_opt[5] * (1.0 - alpha) + var_list_rand[5] * (alpha)\n",
    "    \n",
    "    h1_inter = tf.nn.relu(tf.matmul(x,        h1_W_inter) + h1_b_inter)\n",
    "    h2_inter = tf.nn.relu(tf.matmul(h1_inter, h2_W_inter) + h2_b_inter)\n",
    "    o_inter  = tf.nn.relu(tf.matmul(h2_inter, o_W_inter ) + o_b_inter)\n",
    "    \n",
    "    cost_inter = loss(o_inter, y)\n",
    "    tf.summary.scalar(\"interpolated_cost\", cost_inter)  \n",
    "    \n",
    "#save the parameters for plotting in tensorboard\n",
    "summary_writer = tf.summary.FileWriter(log_files_path + 'linear_interpolation_2/', sess.graph)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "#list to save the results of the following for loop\n",
    "results = []\n",
    "alphaMin = -2\n",
    "alphaMax = 2\n",
    "alphaStep = 0.01\n",
    "for a in np.arange(alphaMin, alphaMax, alphaStep):\n",
    "    #test data with different values of alpha coefficient\n",
    "    feed_dict = {\n",
    "            x: x_test,\n",
    "            y: y_test,\n",
    "            alpha: [[a]],\n",
    "            }\n",
    "    #compute the loss for the different value of alpha\n",
    "    [cost, summary_str] = sess.run([cost_inter, summary_op], feed_dict=feed_dict)\n",
    "    summary_writer.add_summary(summary_str, (a + alphaMax)/alphaStep)\n",
    "    results.append(cost)\n",
    "\n",
    "plt.plot(np.arange(alphaMin, alphaMax, alphaStep), results, 'ro')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dLmgWYWBQ0Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "example_interpolation_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
